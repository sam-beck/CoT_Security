# CoT Multisampling
## Overview
This project implements Chain of Thought (CoT) multisampling for language models, allowing exploration of multiple reasoning paths through tree-structured generation.

The implementation acts as an extension to pytorch's generate function using transformers as the main model handler, enabling multisampling inference with confidence scoring.

This allows for exploring different reasoning structures and analyzing confidence patterns across multiple potential solution paths, using different inference parameters such as temperature, top-p, and number of return sequences to yield a larger distribution of reasoning paths.

[multisampling.py](multisampling.py) contains the core implementation of the multisampling inference, including the recursive token generation function. Each node in the tree is a sequence of tokens generated by the model, and the tree is recursively generated by concatenating the output tokens with the input tokens. The return data structure is a nested list, where each node contains the output tokens and the confidence scores of each token in a sequence (so that the average confidence score of each node can be calculated).

[visualization.py](visualization.py) contains a pyqt5 based gui for visualizing the tree of reasoning paths, allowing for zooming, panning, and node repositioning. This is useful for understanding the structure of the tree and also calculates the average confidence scores of each node sequence.

[example_usage.py](example_usage.py) contains an example of how to use the multisampling inference, including tree visualization.

The [environments](environments) folder contains python environment information for running the project, including the necessary dependencies. It is recommended to use conda to create a new environment and install the dependencies from the .yml file.

## Usage
See [example_usage.py](example_usage.py) for a basic example of how to use the multisampling inference with tree visualization.

### 1. Import basic modules
```python
import torch # Pytorch
from transformers import AutoModelForCausalLM, AutoTokenizer # Transformers library
import multisampling # Multisampling.py
import visualization # Visualization.py
```

### 2. Load model and tokenizer
```python
model = AutoModelForCausalLM.from_pretrained("insert_model_name_here") # Load model
tokenizer = AutoTokenizer.from_pretrained("insert_model_name_here") # Load tokenizer
```

### 3. Define input prompt, input_ids and tree structure
```python
prompt = "input_prompt_here" # Input prompt
input_ids = tokenizer.encode(prompt, return_tensors="pt").to(device) # Encode input prompt
node_structure = [2,1,1] # First node generation has 2 branches, second has 1 branch, third has 1 branch
```

### 4. Generate tree of reasoning paths
```python
output = CoTTreeTokens(
    model=model, # Model
    prompt=input_ids, # Encoded input prompt
    node_structure=node_structure, # nodal structure of tree, where each element is the number of branches from each node
    return_probabilities=True, # Whether to return token probabilities vs raw logits
    temperature=0.9, # Determines randomness of sampling
    top_p=0.8, # Means top 80% of the distribution is considered
    max_new_tokens=50, # Maximum number of tokens to generate, in future this will be dependent on an end-of-thought token (</think>)
    num_beams=1, # The number of beams for beam search; higher values improve quality but increase computation
    pad_token_id=None, # Padding token id
    eos_token_id=None # End of sequence token id
)
```

### 5. Decode and print thought chain (optional)
```python
print(prompt) # Input prompt
print(tokenizer.decode(output[1][0]["output"], skip_special_tokens=True)) # Left output node, depth=1
print(tokenizer.decode(output[1][1][0]["output"], skip_special_tokens=True)) # Left output node of parent node, depth=2
```

### 6. Visualize tree (optional)
```python
app = visualization.QApplication(visualization.sys.argv) # Create application
view = visualization.FlowchartView() # Create window
view.setWindowTitle("CoT Visualization") # Set window title
view.show() # Show window

# Create nodes, parameters are not important as nodes can be repositioned when window is open
visualization.createNodes(view,tokenizer,view.windowWidth/2,0,output,width=350,shiftAmt=600,dropAmt=350,shiftReduction=1.6) 
visualization.sys.exit(app.exec_()) # Exit application when window closed
```








